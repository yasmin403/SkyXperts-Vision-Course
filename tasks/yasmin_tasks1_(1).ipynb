{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "603ac0a1",
      "metadata": {
        "id": "603ac0a1"
      },
      "source": [
        "# Computer Vision Assignments: Sessions 1 & 2\n",
        "\n",
        "This notebook contains tasks and assignments based on Sessions 1 and 2. You are required to implement the functions and complete the exercises as described. Use OpenCV and other necessary libraries like NumPy and Matplotlib.\n",
        "\n",
        "**Instructions:**\n",
        "- Complete each task in the provided code cells.\n",
        "- Test your implementations with sample images (e.g., download test images [here](https://sipi.usc.edu/database/database.php?volume=misc) or [here](https://www.hlevkin.com/hlevkin/06testimages.htm) or use your own test images).\n",
        "- Include comments in your code for clarity.\n",
        "- Display results using cv2.imshow() or Matplotlib where appropriate.\n",
        "- Submit the completed notebook along with any output images or explanations on [our google drive for the CV sessions](https://drive.google.com/drive/folders/1IjVhJmAXxNQTGT-ybJ-yc5smYtR5v8CO?usp=sharing) **upload your files in a new folder under your name**\n",
        "\n",
        "## Session 1: Basic Image Operations (Reading, Resizing, Cropping, Rotating)\n",
        "\n",
        "### Task 1: Read and Display an Image\n",
        "Read an image from a file and display it in both BGR and grayscale formats. Handle errors if the image cannot be read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bo7EgRHmfeLz",
      "metadata": {
        "id": "bo7EgRHmfeLz"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n",
        "\n",
        "# Your code here\n",
        "path = r'/content/sq.jpg'  # Replace with your image path\n",
        "\n",
        "# Read in BGR\n",
        "image = cv.imread(path)\n",
        "print(image.shape)\n",
        "cv2_imshow(image)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Split channels\n",
        "B, G, R = cv.split(image)\n",
        "print(B.shape)\n",
        "\n",
        "cv2_imshow(B)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "cv2_imshow(G)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "cv2_imshow(R)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "matimage = cv.cvtColor(image , cv.COLOR_BGR2RGB)\n",
        "plt.imshow(image)\n",
        "plt.title(\"BGR image\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Read in Grayscale\n",
        "grayimage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "cv2_imshow(grayimage)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Display both using matplotlib\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(cv.cvtColor(image, cv.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Grayscale Image\")\n",
        "plt.imshow(grayimage, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fJdeRI_feL4",
      "metadata": {
        "id": "8fJdeRI_feL4"
      },
      "source": [
        "### Task 2: Resize Image with Aspect Ratio Preservation\n",
        "Implement resizing while preserving aspect ratio. Downscale to 60% and upscale to 200%. Compare shapes and display originals vs resized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HUL0crL5feL5",
      "metadata": {
        "id": "HUL0crL5feL5"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n",
        "\n",
        "# Load image\n",
        "path = r'/content/sq.jpg'\n",
        "image = cv.imread(path)\n",
        "print(image.shape)\n",
        "cv2_imshow(image)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Downscale to 60%\n",
        "Scale_percent = 60\n",
        "h, w, _ = image.shape\n",
        "h = int(Scale_percent * h / 100)\n",
        "w = int(Scale_percent * w / 100)\n",
        "dim = (w, h)  # Note: OpenCV expects (width, height)\n",
        "down_image = cv.resize(image, dim, interpolation=cv.INTER_AREA)\n",
        "\n",
        "# Upscale to 200%\n",
        "Scale_percent = 200\n",
        "h, w, _ = image.shape\n",
        "h = int(Scale_percent * h / 100)\n",
        "w = int(Scale_percent * w / 100)\n",
        "dim = (w, h)\n",
        "UP_image = cv.resize(image, dim, interpolation=cv.INTER_AREA)\n",
        "\n",
        "# Display all three\n",
        "print(\"Downscaled:\", down_image.shape)\n",
        "print(\"Original:\", image.shape)\n",
        "print(\"Upscaled:\", UP_image.shape)\n",
        "\n",
        "cv2_imshow(image)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow(down_image)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow(UP_image)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VS4ugSwQfeL7",
      "metadata": {
        "id": "VS4ugSwQfeL7"
      },
      "source": [
        "### Task 3: Resize Without Preserving Aspect Ratio\n",
        "Resize only width to 100 pixels, only height to 200 pixels, and both to (200, 200). Display and discuss distortions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6uyPyRjWfeL7",
      "metadata": {
        "id": "6uyPyRjWfeL7"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "print(\"Original:\", image.shape)\n",
        "cv2_imshow(image)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Resize only width to 100 pixels\n",
        "h,w , _ = img.shape\n",
        "h = h\n",
        "w = 100\n",
        "dim = (h,w)\n",
        "\n",
        "Width_img = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
        "cv2_imshow( img)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow( Width_img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Resize only height to 200 pixels\n",
        "h,w , _ = img.shape\n",
        "h = 200\n",
        "w = w\n",
        "dim = (h,w)\n",
        "\n",
        "Height_img = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow( Height_img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Resize both to (200, 200)\n",
        "h,w , _ = img.shape\n",
        "h = 200\n",
        "w = 200\n",
        "dim = (h,w)\n",
        "\n",
        "HW_img = cv.resize(img, dim , interpolation = cv.INTER_AREA)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow(HW_img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "x_UvtcMcfeL-",
      "metadata": {
        "id": "x_UvtcMcfeL-"
      },
      "source": [
        "### Task 4: Resize Using Scale Factors (fx, fy)\n",
        "Scale up by 1.2 in both directions and down by 0.6. Use different interpolations (INTER_LINEAR, INTER_NEAREST) and compare quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u4sIh03_feMB",
      "metadata": {
        "id": "u4sIh03_feMB"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "print(\"Original:\", img.shape)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Scaling factors\n",
        "scale_up_x = 1.2\n",
        "scale_up_y = 1.2\n",
        "scale_down = 0.6\n",
        "\n",
        "# Resize down using INTER_LINEAR\n",
        "scaled_f_down = cv.resize(img, None, fx=scale_down, fy=scale_down, interpolation=cv.INTER_LINEAR)\n",
        "\n",
        "# Resize up using INTER_LINEAR\n",
        "scaled_f_up = cv.resize(img, None, fx=scale_up_x, fy=scale_up_y, interpolation=cv.INTER_LINEAR)\n",
        "\n",
        "# Resize up using INTER_CUBIC\n",
        "scaled_up_cubic = cv.resize(img, None, fx=scale_up_x, fy=scale_up_y, interpolation=cv.INTER_CUBIC)\n",
        "\n",
        "\n",
        "# Display all results\n",
        "print(\"Scaled Down (INTER_LINEAR):\", scaled_f_down.shape)\n",
        "cv2_imshow(scaled_f_down)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "print(\"Scaled Up (INTER_LINEAR):\", scaled_f_up.shape)\n",
        "cv2_imshow(scaled_f_up)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "print(\"Scaled Up (INTER_CUBIC):\", scaled_up_cubic.shape)\n",
        "cv2_imshow(scaled_up_cubic)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kzMJIXYafeMD",
      "metadata": {
        "id": "kzMJIXYafeMD"
      },
      "source": [
        "### Task 5: Cropping an Image\n",
        "Crop a region (e.g., [20:200, 50:200]) from the image. Display original and cropped."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vsT4y8PGfeME",
      "metadata": {
        "id": "vsT4y8PGfeME"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Load image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "print(\"Original:\", img.shape)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "Cropped_img = img [20:200 , 50:200]\n",
        "cv2_imshow(  img)\n",
        "cv.waitKey(0)\n",
        "cv2_imshow(Cropped_img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "F01U9JiGfeME",
      "metadata": {
        "id": "F01U9JiGfeME"
      },
      "source": [
        "### Task 6: Advanced Cropping - Patch Image into Blocks\n",
        "Divide the image into 4 equal blocks (2x2 grid) by cropping. Display each block separately and then stitch them back using NumPy concatenation to verify."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j53SLK-GfeMF",
      "metadata": {
        "id": "j53SLK-GfeMF"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "path = r'/content/sq.jpg'\n",
        "image = cv.imread(path)\n",
        "#---------------------------\n",
        "\n",
        "# Calculate midpoints for height and width\n",
        "height, width, _ = image.shape\n",
        "h_mid = height // 2\n",
        "w_mid = width // 2\n",
        "\n",
        "\n",
        "# Crop into top-left, top-right, bottom-left, bottom-right\n",
        "top_left = image[0:h_mid, 0:w_mid]\n",
        "top_right = image[0:h_mid, w_mid:width]\n",
        "bottom_left = image[h_mid:height, 0:w_mid]\n",
        "bottom_right = image[h_mid:height, w_mid:width]\n",
        "\n",
        "# Display each\n",
        "\n",
        "cv2_imshow(top_left)\n",
        "cv2_imshow(top_right)\n",
        "cv2_imshow(bottom_left)\n",
        "cv2_imshow(bottom_right)\n",
        "\n",
        "\n",
        "# Stitch back (use np.hstack and np.vstack)\n",
        "top_row = np.hstack((top_left, top_right))\n",
        "bottom_row = np.hstack((bottom_left, bottom_right))\n",
        "stitched_image = np.vstack((top_row, bottom_row))\n",
        "\n",
        "cv2_imshow(stitched_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3MU05obxfeMF",
      "metadata": {
        "id": "3MU05obxfeMF"
      },
      "source": [
        "### Task 7: Rotating an Image\n",
        "Rotate the image by 45°, 90°, and 180° using getRotationMatrix2D and warpAffine. Display all rotations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uP4BRFTUfeMG",
      "metadata": {
        "id": "uP4BRFTUfeMG"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "print(\"Original:\", img.shape)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Calculate center\n",
        "height, width, _ = img.shape\n",
        "center = (width / 2, height / 2)\n",
        "\n",
        "rotate_matrix_45 = cv.getRotationMatrix2D(center=center, angle=45, scale=1)\n",
        "rotate_matrix_90 = cv.getRotationMatrix2D(center=center, angle=90, scale=1)\n",
        "rotate_matrix_180 = cv.getRotationMatrix2D(center=center, angle=180, scale=1)\n",
        "\n",
        "\n",
        "rotated_image_45 = cv.warpAffine(src=img, M=rotate_matrix_45, dsize=(width, height))\n",
        "rotated_image_90 = cv.warpAffine(src=img, M=rotate_matrix_90, dsize=(width, height))\n",
        "rotated_image_180 = cv.warpAffine(src=img, M=rotate_matrix_180, dsize=(width, height))\n",
        "\n",
        "# Display results\n",
        "print(\"Rotated 45°:\", rotated_image_45.shape)\n",
        "cv2_imshow(rotated_image_45)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "print(\"Rotated 90°:\", rotated_image_90.shape)\n",
        "cv2_imshow(rotated_image_90)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "print(\"Rotated 180°:\", rotated_image_180.shape)\n",
        "cv2_imshow(rotated_image_180)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XPF5YhOnfeMG",
      "metadata": {
        "id": "XPF5YhOnfeMG"
      },
      "source": [
        "### Task 8: Rotate with Scaling\n",
        "Rotate by 45° and scale by 0.5 in **one** operation. Compare with separate resize and rotate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rfm8HW9kfeMH",
      "metadata": {
        "id": "rfm8HW9kfeMH"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "print(\"Original:\", img.shape)\n",
        "cv2_imshow(img)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "\n",
        "# Calculate center\n",
        "height, width, _ = img.shape\n",
        "center = (width / 2, height / 2)\n",
        "\n",
        "# Rotate by 45° and scale by 0.5\n",
        "rotate_matrix_45 = cv.getRotationMatrix2D(center=center, angle=45, scale=0.5)\n",
        "rotate_scaled_45 = cv.warpAffine(img, rotate_matrix_45, (width, height))\n",
        "\n",
        "# Display result\n",
        "print(\"Rotated + Scaled:\", rotate_scaled_45.shape)\n",
        "cv2_imshow(rotate_scaled_45)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6lC2FOsxfeMH",
      "metadata": {
        "id": "6lC2FOsxfeMH"
      },
      "source": [
        "## Session 2: Image Acquisition, Formats, Color Spaces, Enhancement, and Filtering\n",
        "\n",
        "### Task 9: Read Image in Different Color Spaces\n",
        "Read an image in BGR, convert to RGB (for Matplotlib), HSV, LAB and Grayscale. Display all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9vBK350hfeMH",
      "metadata": {
        "id": "9vBK350hfeMH"
      },
      "outputs": [],
      "source": [
        "\n",
        "    # Convert to RGB (for Matplotlib display)\n",
        "img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "\n",
        "    # Convert to HSV\n",
        "img_hsv = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
        "\n",
        "    # Convert to LAB\n",
        "img_lab = cv.cvtColor(img, cv.COLOR_BGR2Lab)\n",
        "\n",
        "    # Convert to Grayscale\n",
        "img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "print(\"BGR  \")\n",
        "cv2_imshow(img)\n",
        "\n",
        "print(\"RGB  \")\n",
        "cv2_imshow(img_rgb)\n",
        "\n",
        "print(\"HSV  \")\n",
        "cv2_imshow(img_hsv)\n",
        "\n",
        "print(\"LAB  \")\n",
        "cv2_imshow(img_lab)\n",
        "\n",
        "print(\"Grayscale:\")\n",
        "cv2_imshow(img_gray)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jkEEUfVjfeMI",
      "metadata": {
        "id": "jkEEUfVjfeMI"
      },
      "source": [
        "### Task 10: Image Sharpening\n",
        "Apply cv2.blur() with a 5x5 kernel, then use cv2.filter2D() with sharpening kernels of varying strengths (e.g., [[0, -1, 0], [-1, 5, -1], [0, -1, 0]] and [[0, -2, 0], [-2, 9, -2], [0, -2, 0]]).\n",
        "Compare between original and sharpened image after blurring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c27urg0JfeMI",
      "metadata": {
        "collapsed": true,
        "id": "c27urg0JfeMI"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "\n",
        "# Check if image is loaded\n",
        "if img is None:\n",
        "    print(\"Error: Image not found.\")\n",
        "else:\n",
        "\n",
        "    blurred = cv.blur(img, (5, 5))\n",
        "\n",
        "    sharpen_kernel_mild = np.array([[0, -1, 0],\n",
        "                                    [-1, 5, -1],\n",
        "                                    [0, -1, 0]], dtype=np.float32)\n",
        "\n",
        "    sharpen_kernel_strong = np.array([[0, -2, 0],\n",
        "                                      [-2, 9, -2],\n",
        "                                      [0, -2, 0]], dtype=np.float32)\n",
        "\n",
        "\n",
        "    sharpened_mild = cv.filter2D(blurred, -1, sharpen_kernel_mild)\n",
        "    sharpened_strong = cv.filter2D(blurred, -1, sharpen_kernel_strong)\n",
        "\n",
        "\n",
        "print(\"Original Image:\")\n",
        "cv2_imshow(img)\n",
        "print(\"Blurred (5x5):\")\n",
        "cv2_imshow(blurred)\n",
        "print(\"Sharpened with Kernel  mild:\")\n",
        "cv2_imshow( sharpened_mild )\n",
        "print(\"Sharpened with Kernel strong:\")\n",
        "cv2_imshow( sharpened_strong )"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JcFI_w3b8lHY"
      },
      "id": "JcFI_w3b8lHY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "efVej1vjfeMI",
      "metadata": {
        "id": "efVej1vjfeMI"
      },
      "source": [
        "### Task 11: Add Salt and Pepper Noise to Image\n",
        "Implement a function to add salt and pepper noise to an image. Control noise density (e.g., 0.05)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ryc3X0B_480t",
      "metadata": {
        "id": "Ryc3X0B_480t"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "from skimage.util import random_noise\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def add_salt_pepper_noise(image, density=0.05):\n",
        "    noisy = random_noise(image, mode='s&p', amount=density)\n",
        "    return (255 * noisy).astype(np.uint8)\n",
        "# Apply to an image and display"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NOEWxHtafeMJ",
      "metadata": {
        "id": "NOEWxHtafeMJ"
      },
      "source": [
        "### Task 12: Remove Salt and Pepper Noise Using Median Filter\n",
        "Apply cv.medianBlur() to a noisy image. Experiment with kernel sizes (3,5,7) and compare results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-okOVkL_feMJ",
      "metadata": {
        "collapsed": true,
        "id": "-okOVkL_feMJ"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.util import random_noise\n",
        "def add_salt_pepper_noise(image, density=0.05):\n",
        "\n",
        "    noisy = img.copy()\n",
        "    h, w = img.shape[:2]\n",
        "    num_noise = int(density * h * w)  # total noisy pixels\n",
        "\n",
        "    # Add salt (white) pixels\n",
        "    coords = [np.random.randint(0, i - 1, num_noise) for i in (h, w)]\n",
        "    noisy[coords[0], coords[1]] = 255\n",
        "\n",
        "    # Add pepper (black) pixels\n",
        "    coords = [np.random.randint(0, i - 1, num_noise) for i in (h, w)]\n",
        "    noisy[coords[0], coords[1]] = 0\n",
        "\n",
        "    return noisy\n",
        "\n",
        "# Load the image\n",
        "path = '/content/sq.jpg'\n",
        "img = cv.imread(path)\n",
        "     # Step 1: Add noise\n",
        "noisy_img = add_salt_pepper_noise(img, density=0.05)\n",
        "\n",
        "\n",
        "median3 = cv.medianBlur(noisy_img, 3)\n",
        "median5 = cv.medianBlur(noisy_img, 5)\n",
        "median7 = cv.medianBlur(noisy_img, 7)\n",
        "\n",
        "\n",
        "print(\"Original Image:\")\n",
        "cv2_imshow(img)\n",
        "\n",
        "print(\"Noisy Image:\")\n",
        "cv2_imshow(noisy_img)\n",
        "print(\"Median Filter (3x3 ):\")\n",
        "cv2_imshow(median3)\n",
        "print(\"Median Filter (5x5 ):\")\n",
        "cv2_imshow(median5)\n",
        "print(\"Median Filter (7x7 ):\")\n",
        "cv2_imshow(median7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EgosHoeEfeMJ",
      "metadata": {
        "id": "EgosHoeEfeMJ"
      },
      "source": [
        "### Task 13: Implement Adaptive Median Filter\n",
        "Write a custom function for adaptive median filtering. It should dynamically increase window size until noise is removed or max size is reached. Apply to a noisy image and compare with standard median."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AjrPa35qfeMJ",
      "metadata": {
        "id": "AjrPa35qfeMJ"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "\n",
        "def adaptive_median_filter(image, max_size=7):\n",
        "\n",
        "    padded = cv.copyMakeBorder(image, max_size//2, max_size//2, max_size//2, max_size//2, cv.BORDER_REFLECT)\n",
        "    output = np.zeros_like(image)\n",
        "    rows, cols = image.shape\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            window_size = 3\n",
        "            while window_size <= max_size:\n",
        "                half = window_size // 2\n",
        "                region = padded[i:i+window_size, j:j+window_size]\n",
        "                Zmin = np.min(region)\n",
        "                Zmax = np.max(region)\n",
        "                Zmed = np.median(region)\n",
        "                Zxy = padded[i+half, j+half]\n",
        "\n",
        "                if Zmed > Zmin and Zmed < Zmax:\n",
        "                    if Zxy > Zmin and Zxy < Zmax:\n",
        "                        output[i, j] = Zxy\n",
        "                    else:\n",
        "                        output[i, j] = Zmed\n",
        "                    break\n",
        "                else:\n",
        "                    window_size += 2\n",
        "            else:\n",
        "                output[i, j] = Zmed\n",
        "    return output\n",
        "\n",
        "\n",
        "# Test on noisy image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Sm-vFN8XfeMK",
      "metadata": {
        "id": "Sm-vFN8XfeMK"
      },
      "source": [
        "### Task 14: Implement Bilateral Filter Function\n",
        "Write a Python function to perform bilateral filtering on an image. Use Gaussian weights for both spatial and intensity. Parameters: diameter, sigma_color, sigma_space. Compare with cv.bilateralFilter()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KDnFS1CEfeMK",
      "metadata": {
        "id": "KDnFS1CEfeMK"
      },
      "outputs": [],
      "source": [
        "def custom_bilateral_filter(image, diameter, sigma_color, sigma_space):\n",
        "\n",
        "    if image.ndim != 2:\n",
        "        raise ValueError(\"Only grayscale images supported.\")\n",
        "\n",
        "    padded = cv.copyMakeBorder(image, diameter//2, diameter//2, diameter//2, diameter//2, cv.BORDER_REFLECT)\n",
        "    output = np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "    half = diameter // 2\n",
        "    rows, cols = image.shape\n",
        "\n",
        "    # Precompute spatial Gaussian kernel\n",
        "    x, y = np.meshgrid(np.arange(-half, half+1), np.arange(-half, half+1))\n",
        "    spatial_kernel = np.exp(-(x**2 + y**2) / (2 * sigma_space**2))\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            region = padded[i:i+diameter, j:j+diameter]\n",
        "            center_val = padded[i+half, j+half]\n",
        "\n",
        "            intensity_kernel = np.exp(-((region - center_val)**2) / (2 * sigma_color**2))\n",
        "            combined_kernel = spatial_kernel * intensity_kernel\n",
        "            combined_kernel /= np.sum(combined_kernel)\n",
        "\n",
        "            output[i, j] = np.sum(region * combined_kernel)\n",
        "\n",
        "    return np.uint8(output)\n",
        "\n",
        "\n",
        "# Apply to image, display, and compare with OpenCV's version"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jxahZcZKfeML",
      "metadata": {
        "id": "jxahZcZKfeML"
      },
      "source": [
        "### [BONUS] Task 15: Comprehensive Camera Task\n",
        "Combine: Live camera feed -> grayscale -> add noise -> remove with median -> sharpen. Display all stages in separate windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oJ493O4uoui-",
      "metadata": {
        "id": "oJ493O4uoui-"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def add_salt_pepper_noise(image, amount=0.02):\n",
        "    \"\"\"Add salt and pepper noise to a grayscale image.\"\"\"\n",
        "    noisy = image.copy()\n",
        "    total_pixels = image.shape[0] * image.shape[1]\n",
        "    num_salt = int(amount * total_pixels / 2)\n",
        "    num_pepper = int(amount * total_pixels / 2)\n",
        "\n",
        "    for _ in range(num_salt):\n",
        "        i = np.random.randint(0, image.shape[0])\n",
        "        j = np.random.randint(0, image.shape[1])\n",
        "        noisy[i, j] = 255\n",
        "\n",
        "    for _ in range(num_pepper):\n",
        "        i = np.random.randint(0, image.shape[0])\n",
        "        j = np.random.randint(0, image.shape[1])\n",
        "        noisy[i, j] = 0\n",
        "\n",
        "    return noisy\n",
        "\n",
        "# Sharpening kernel\n",
        "sharpen_kernel = np.array([[0, -1, 0],\n",
        "                           [-1, 5, -1],\n",
        "                           [0, -1, 0]])\n",
        "\n",
        "# Load video file instead of camera\n",
        "video_path = '/content/video1.mp4'  # Make sure this file is uploaded\n",
        "cap = cv.VideoCapture(video_path)\n",
        "\n",
        "# Output video writer\n",
        "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv.VideoWriter('processed_video.mp4', fourcc, 20.0, (480, 360), isColor=False)\n",
        "\n",
        "frame_count = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    frame = cv.resize(frame, (480, 360))\n",
        "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "    noisy = add_salt_pepper_noise(gray, amount=0.02)\n",
        "    denoised = cv.medianBlur(noisy, 5)\n",
        "    sharpened = cv.filter2D(denoised, -1, sharpen_kernel)\n",
        "\n",
        "    # Save final processed frame\n",
        "    out.write(sharpened)\n",
        "\n",
        "    # Display all stages (one at a time to avoid clutter)\n",
        "    print(f\"Frame {frame_count}\")\n",
        "    cv2_imshow(gray)\n",
        "    cv2_imshow(noisy)\n",
        "    cv2_imshow(denoised)\n",
        "    cv2_imshow(sharpened)\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\" Video processing complete. Saved as 'processed_video.mp4'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O4OyewbqfeML",
      "metadata": {
        "id": "O4OyewbqfeML"
      },
      "source": [
        "### [BONUS]Task 16: Comprehensive Video Task\n",
        "Similar to Task 18 but for a video file. Save the final processed video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pcBKm4c-feMM",
      "metadata": {
        "id": "pcBKm4c-feMM"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow  # For display in Colab\n",
        "\n",
        "# Function to add salt and pepper noise\n",
        "def add_salt_pepper_noise(image, amount=0.02):\n",
        "    noisy = image.copy()\n",
        "    total_pixels = image.shape[0] * image.shape[1]\n",
        "    num_salt = int(amount * total_pixels / 2)\n",
        "    num_pepper = int(amount * total_pixels / 2)\n",
        "\n",
        "    for _ in range(num_salt):\n",
        "        i = np.random.randint(0, image.shape[0])\n",
        "        j = np.random.randint(0, image.shape[1])\n",
        "        noisy[i, j] = 255\n",
        "\n",
        "    for _ in range(num_pepper):\n",
        "        i = np.random.randint(0, image.shape[0])\n",
        "        j = np.random.randint(0, image.shape[1])\n",
        "        noisy[i, j] = 0\n",
        "\n",
        "    return noisy\n",
        "\n",
        "# Sharpening kernel\n",
        "sharpen_kernel = np.array([[0, -1, 0],\n",
        "                           [-1, 5, -1],\n",
        "                           [0, -1, 0]])\n",
        "\n",
        "# Load video\n",
        "video_path = '/content/video1.mp4'\n",
        "cap = cv.VideoCapture(video_path)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Cannot open video file.\")\n",
        "else:\n",
        "    # Output video writer\n",
        "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv.VideoWriter('processed_video.mp4', fourcc, 20.0, (480, 360), isColor=False)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize and convert to grayscale\n",
        "        frame = cv.resize(frame, (480, 360))\n",
        "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Add noise, denoise, and sharpen\n",
        "        noisy = add_salt_pepper_noise(gray, amount=0.02)\n",
        "        denoised = cv.medianBlur(noisy, 5)\n",
        "        sharpened = cv.filter2D(denoised, -1, sharpen_kernel)\n",
        "\n",
        "        # Save processed frame\n",
        "        out.write(sharpened)\n",
        "\n",
        "        # Optional: Display processed frame\n",
        "        cv2_imshow(sharpened)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\" Video processing complete. Saved as 'processed_video.mp4'\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UFHNqJLsfeMN",
      "metadata": {
        "id": "UFHNqJLsfeMN"
      },
      "source": [
        "### Task 17: Performance Comparison\n",
        "Time the execution of standard median vs adaptive median on a large noisy image. Discuss when adaptive median filter is better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DrZ5ExHQfeMO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrZ5ExHQfeMO",
        "outputId": "23815ba5-d767-4ed6-eb6d-fa2d2f643993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Median Time: 0.00 seconds\n",
            "Adaptive Median Time: 20.31 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "# Your code here\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def adaptive_median_filter(image, max_size=7):\n",
        "    padded = cv.copyMakeBorder(image, max_size//2, max_size//2, max_size//2, max_size//2, cv.BORDER_REFLECT)\n",
        "    output = np.zeros_like(image)\n",
        "    rows, cols = image.shape\n",
        "\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            window_size = 3\n",
        "            while window_size <= max_size:\n",
        "                half = window_size // 2\n",
        "                region = padded[i:i+window_size, j:j+window_size]\n",
        "                Zmin = np.min(region)\n",
        "                Zmax = np.max(region)\n",
        "                Zmed = np.median(region)\n",
        "                Zxy = padded[i+half, j+half]\n",
        "\n",
        "                if Zmed > Zmin and Zmed < Zmax:\n",
        "                    if Zxy > Zmin and Zxy < Zmax:\n",
        "                        output[i, j] = Zxy\n",
        "                    else:\n",
        "                        output[i, j] = Zmed\n",
        "                    break\n",
        "                else:\n",
        "                    window_size += 2\n",
        "            else:\n",
        "                output[i, j] = Zmed\n",
        "    return output\n",
        "\n",
        "# Load and prepare image\n",
        "img = cv.imread('/content/sq.jpg', cv.IMREAD_GRAYSCALE)\n",
        "img = cv.resize(img, (800, 800))\n",
        "# Initialize noisy with integer type and add salt and pepper noise\n",
        "noisy = img.copy().astype(np.uint8)\n",
        "noise_mask = np.random.rand(*img.shape)\n",
        "noisy = np.where(noise_mask < 0.025, 0, noisy) # Pepper noise\n",
        "noisy = np.where(noise_mask > 0.975, 255, noisy) # Salt noise\n",
        "\n",
        "# Time standard median\n",
        "start_std = time.time()\n",
        "median_std = cv.medianBlur(noisy, 5)\n",
        "end_std = time.time()\n",
        "\n",
        "# Time adaptive median\n",
        "start_adapt = time.time()\n",
        "median_adapt = adaptive_median_filter(noisy, max_size=7)\n",
        "end_adapt = time.time()\n",
        "\n",
        "print(f\"Standard Median Time: {end_std - start_std:.2f} seconds\")\n",
        "print(f\"Adaptive Median Time: {end_adapt - start_adapt:.2f} seconds\")\n",
        "\n",
        "# Use time.time() to measure"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}